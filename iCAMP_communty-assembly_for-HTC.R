### This code is likely best used on a high-throughput computing cluster.
### This code is based on Ning et al., 2020
### found at https://github.com/DaliangNing/iCAMP1

# key parameter setting
bin.size.limit = 24
prefix="Exp3_Lan_icamp_24_bMNTD"  # prefix of the output file names. usually use a project ID.
rand.time=1000  # randomization time, 1000 is usually enough. For example test, you may set as 100 or less to save time.
nworker=8 # nworker is thread number for parallel computing, which depends on the CPU core number of your computer.
memory.G=50 # to set the memory size as you need (but should be less than the available space in your hard disk), so that calculation of large tree will not be limited by physical memory. unit is Gb.

# 1 # set file names

# the OTU table file (Tab delimited txt file)
com.file="otus.txt"

# the phylogenetic tree file
tree.file="tree_rooted_Exp3.nwk"

# the classification (taxonomy) information
clas.file="classification.txt"

# the treatment information table
treat.file="treat2col_Lan.txt"

# the environmental variables
env.file="environment.txt"
# if you do not have env file or the env may not represent niche, skip step 7 and 8, but check the alternative way to determine binning setting, e.g. bin.size.limit.

# metacommunity file, to determine null model pool
meta.file="meta_Lan.txt"

# 3 # load R packages and data
library(iCAMP)
library(ape)

comm=t(read.table(com.file, header = TRUE, sep = "\t", row.names = 1,
                  as.is = TRUE, stringsAsFactors = FALSE, comment.char = "",
                  check.names = FALSE))

tree=read.tree(file = tree.file)

clas=read.table(clas.file, header = TRUE, sep = "\t", row.names = 1,
                as.is = TRUE, stringsAsFactors = FALSE, comment.char = "",
                check.names = FALSE)
treat=read.table(treat.file, header = TRUE, sep = "\t", row.names = 1,
                 as.is = TRUE, stringsAsFactors = FALSE, comment.char = "",
                 check.names = FALSE)

env=read.table(env.file, header = TRUE, sep = "\t", row.names = 1,
               as.is = TRUE, stringsAsFactors = FALSE, comment.char = "",
               check.names = FALSE) # skip this if you do not have env.file

meta.group=read.table(meta.file, header = TRUE, sep = "\t", row.names = 1,
                as.is = TRUE, stringsAsFactors = FALSE, comment.char = "",
                check.names = FALSE) # skip this if you do not have meta.file


# 4 # match sample IDs in OTU table and treatment information table
sampid.check=match.name(rn.list=list(comm=comm,treat=treat,env=env))
treat=sampid.check$treat
comm=sampid.check$comm
comm=comm[,colSums(comm)>0,drop=FALSE] 
env=sampid.check$env

# 5 # match OTU IDs in OTU table and tree file
spid.check=match.name(cn.list=list(comm=comm),rn.list=list(clas=clas),tree.list=list(tree=tree))
comm=spid.check$comm
clas=spid.check$clas
tree=spid.check$tree

# 6 # calculate pairwise phylogenetic distance matrix.
save.wd="Output"
if(!dir.exists(save.wd)){dir.create(save.wd)}
setwd(save.wd)
if(!file.exists("pd.desc")) {
  pd.big=iCAMP::pdist.big(tree = tree, wd=getwd(), nworker = nworker, memory.G = memory.G)
  # output files:
  # path.rda: a R object to list all the nodes and edge lengths from root to every tip. saved in R data format. an intermediate output when calculating phylogenetic distance matrix.
  # pd.bin: BIN file (backingfile) generated by function big.matrix in R package bigmemory. This is the big matrix storing pairwise phylogenetic distance values. By using this bigmemory format file, we will not need memory but hard disk when calling big matrix for calculation.
  # pd.desc: the DESC file (descriptorfile) to hold the backingfile (pd.bin) description.
  # pd.taxon.name.csv: comma delimited csv file storing the IDs of tree tips (OTUs), serving as the row/column names of the big phylogenetic distance matrix.
} else {
  # if you already calculated the phylogenetic distance matrix in a previous run
  pd.big=list()
  pd.big$tip.label=read.csv(paste0(save.wd,"/pd.taxon.name.csv"),row.names = 1,stringsAsFactors = FALSE)[,1]
  pd.big$pd.wd=save.wd
  pd.big$pd.file="pd.desc"
  pd.big$pd.name.file="pd.taxon.name.csv"
}

####################
# # you may skip step 7-8, if the "alternative way" based on stochasticity is applicable, as mentioned in the method part of iCAMP paper (Ning et al 2020 Nature Communications).
# # 7 # assess niche preference difference between species
# # env is required for this step.
# # since microbial community data usually has a large number of species (OTUs or ASVs), we use "big.matrix" in R package "bigmemory" to handle the large niche difference matrix.

niche.dif=iCAMP::dniche(env = env,comm = comm, method = "niche.value",
                        nworker = nworker,out.dist=FALSE,bigmemo=FALSE, # PREVIOUSLY TRUE
                        nd.wd=save.wd)

# # 8 # within-bin phylogenetic signal assessment.
# # For real data, you may try several different settings of binning, and choose the one leading to the best within-bin phylogenetic signal.
# # env is required for this step.
# # 8.1 # try phylogenetic binning using current settings.
ds = 0.2 # setting can be changed to explore the best choice
phylobin=taxa.binphy.big(tree = tree, pd.desc = pd.big$pd.file,pd.spname = pd.big$tip.label,
                         pd.wd = pd.big$pd.wd, ds = ds, bin.size.limit = bin.size.limit,
                         nworker = nworker)

# # 8.2 # test within-bin phylogenetic signal.
sp.bin=phylobin$sp.bin[,3,drop=FALSE]
sp.ra=colMeans(comm/rowSums(comm))
abcut=3 # you may remove some species, if they are too rare to perform reliable correlation test.
commc=comm[,colSums(comm)>=abcut,drop=FALSE]
dim(commc)
spname.use=colnames(commc)
binps=iCAMP::ps.bin(sp.bin = sp.bin,sp.ra = sp.ra,spname.use = spname.use,
                    pd.desc = pd.big$pd.file, pd.spname = pd.big$tip.label, pd.wd = pd.big$pd.wd,
                    nd.list = niche.dif$nd,nd.spname = niche.dif$names,ndbig.wd = niche.dif$nd.wd,
                    cor.method = "pearson",r.cut = 0.1, p.cut = 0.05, min.spn = 5)
if(file.exists(paste0(prefix,".PhyloSignalSummary.csv"))){appendy=TRUE;col.namesy=FALSE}else{appendy=FALSE;col.namesy=TRUE}
write.table(data.frame(ds=ds,n.min=bin.size.limit,binps$Index),file = paste0(prefix,".PhyloSignalSummary.csv"),
            append = appendy, quote=FALSE, sep=",", row.names = FALSE,col.names = col.namesy)
if(file.exists(paste0(prefix,".PhyloSignalDetail.csv"))){appendy2=TRUE;col.namesy2=FALSE}else{appendy2=FALSE;col.namesy2=TRUE}
write.table(data.frame(ds=ds,n.min=bin.size.limit,binID=rownames(binps$detail),binps$detail),file = paste0(prefix,".PhyloSignalDetail.csv"),
            append = appendy2, quote = FALSE, sep = ",", row.names = FALSE, col.names = col.namesy2)
# # You are looking for a binning setting lead to higher RAsig.abj (relative abundance of bins with significant phylogenetic signal) 
# # and relative high meanR (mean correlation coefficient across bins).

# ####################
# 9 # iCAMP analysis
# ...without omitting small bins
taxo.metric='bray'
transform.method='hellinger'
sig.index="Confidence" # see other options in help document of icamp.big.
icres=iCAMP::icamp.big(comm=comm, tree=tree,
                      #meta.group = meta.group, # Use this line when running icamp.cm instead of icamp.big
                      pd.desc = pd.big$pd.file, pd.spname=pd.big$tip.label, pd.wd = pd.big$pd.wd, pd.cut = NA,
                      treepath.file = "path.rda",
                      pd.spname.file = "pd.taxon.name.csv", pd.backingfile = "pd.bin", pd.desc.file = "pd.desc", 
                      bin.size.limit = bin.size.limit, rand = rand.time, nworker = nworker, memory.G = memory.G, 
                      ds = 0.2,	sp.check = TRUE, 
                      phylo.rand.scale = "within.bin",
	                    taxa.rand.scale = "across.all",
                      phylo.metric = "bMNTD",
			                taxo.metric = taxo.metric,
			                sig.index=sig.index,
                      rtree.save = FALSE, detail.save = TRUE, qp.save = TRUE, #output.wd = save.wd,
			                detail.null = FALSE, ignore.zero = TRUE,
                      correct.special = TRUE, unit.sum = rowSums(comm),
			                special.method = "depend",
                      ses.cut = 1.96, rc.cut = 0.95, conf.cut=0.975, omit.option = "no",
                      transform.method = transform.method)
warnings()

# there are quite a few parameters in this function, please check the help document of "icamp.big".
# output files:
# Test.iCAMP.detail.rda: the object "icres" saved in R data format. it is a list object.
# The first element bNRIiRCa is the result of relative importance of each assembly process in each
# pairwise comparison (each turnover). The second element "detail" including binning information
# (named taxabin), phylogenetic and taxonomic metrics results in each bin (named like bNRIi, RCa, etc.),
# relative abundance of each bin (bin.weight), relative importance of each process in each turnover
# between communities (processes), input settings (setting), and input community data matrix
# (comm). See help document of the function icamp.big for more details.
# 
# ############################

### I did not use the rest of the optional tests and analyses that are included in the example code available on Ning's github.